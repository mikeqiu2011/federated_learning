# Simple Federated Learning System: Educational Version

[comment]: <> (![logo]&#40;docs/_src/_static/logo.png&#41;)


<!-- STADLE platform is a paradigm-shifting technology combining Machine Learning (ML) and decentralized system capability to provide scalable, versatile, and privacy-preserving AI services and applications. 
STADLE stands for Scalable, Traceable, Adaptive, Distributed LEarning.  -->
This repo is the free trial version of a simple federated learning system that is designed with only for educational and R&D purposes to understand the basics of federated learning with minimum architectures and functionalities.
For a commercial version, please contact TieSet Inc. at info@tie-set.com.

Federated Learning (FL) solves many problems of privacy and communication load, which commonly appear in ML systems. FL does not require users to upload raw data to cloud servers.
- Privacy: FL improves the privacy-preserving aspect of AI systems by not collecting data in the cloud while producing collective intelligence based on uploaded user ML models. 
- Communication load: The amount of traffic generated by FL dramatically decreases from classical AI systems due to the difference in data type exchanged.

There are a lot more merits that federated learning systems can provide.

<!-- Our STADLE platform enhances the capability of FL by incorporating decentralized architecture.
- Scalability: Decentralized FL servers in STADLE realizes the load-balancing to accommodate more users.
- 5G-friendliness: The delay in communication to obtain collective intelligence can be dramatically reduced by employing decentralized FL servers located at edge servers.
- Traceability: Our platform has the performance tracking capability that monitors and manages the transition of collective intelligence models in the decentralized system. -->

## Table of Contents
- [Simple FL System: Educational Version](#stadle-v10)
  - [Simple FL Package](#Simple-FL-Package)
  - [Install](#install)
  - [Usage](#usage)
    - [Minimal Example](#minimal-example)
      - [Sample Execution](#sample-execution)
      - [Simulation](#simulation)
    - [Image Classification Application](#image-classification-application)
  <!-- - [Documentation](#documentation) -->
  - [Contributing](#contributing)
  <!-- - [License](#license) -->


## Simple FL Package

### ```examples``` directory
Sample ML Engine codes that integrate FL client side libraries.

### ```fl_main``` directory
Agent, aggregator, database codes together with supporting libraries.

### ```setups``` directory
Configulation files with JSON format and installation yaml files.


## Install
For all the environments of FL Server (Aggregator), FL Client (Agent), and Database Server, please create conda environment and activate it.

```sh
# macOS
conda env create -n federatedenv -f ./setups/federatedenv.yaml
# Linux
conda env create -n federatedenv -f ./setups/federatedenv_linux.yaml
```

[comment]: <> (### FL Client &#40;Agent&#41; )

[comment]: <> (```sh)

[comment]: <> (# macOS)

[comment]: <> (conda env create -n federatedenv -f ./setups/federatedenv.yaml)

[comment]: <> (# Linux)

[comment]: <> (conda env create -n federatedenv -f ./setups/federatedenv_linux.yaml)

[comment]: <> (```)


[comment]: <> (### Database Server)

[comment]: <> (```sh)

[comment]: <> (# macOS)

[comment]: <> (conda env create -n federatedenv -f ./setups/federatedenv.yaml)

[comment]: <> (# Linux)

[comment]: <> (conda env create -n federatedenv -f ./setups/federatedenv_linux.yaml)

[comment]: <> (```)

Be sure to do ```conda activate federatedenv``` when you run the codes.

Note: The environment has ```Python 3.7.4```. There is some known issues of ```ipfshttpclient``` with ```Python 3.7.2 and older```.


## Usage
### [Minimal Example](examples/minimal)

This sample does not have actual training. This could be used as a template for user implementation of ML Engine.
#### Sample Execution
1. Edit the configuration files in the setups folder. The configuration details are explained [here](setups/).
2. Run the following 3 modules as separated processes in the order of ```pseudo_db``` -> ```server_th``` -> ```minimal_MLEngine```.

```python
python -m fl_main.pseudodb.pseudo_db
python -m fl_main.aggregator.server_th
python -m examples.minimal.minimal_MLEngine
```
#### Simulation
*Beta-ver*: FL systems can be run for simulation on the same machine by specifying the port numbers for agents and aggregators. 
```python
python -m fl_main.pseudodb.pseudo_db [simulation_flag] [config_path]
python -m fl_main.aggregator.server_th [simulation_flag] [participation_port] [local_model_recv_port] [config_path]
python -m examples.minimal.minimal_MLEngine [simulation_flag] [participation_port] [local_model_recv_port] [path_to_local_file] [config_path]
```
##### Common
- ```simulation_flag```: 1 if it's simulation
- ```config_path```: Path to the config file. If ```AUTO```, the config file in ```(repo root)/setups/config.json```. (For the consistency with older versions, it automatically sets this flag to ```AUTO``` when no flag is given.)
##### Aggregator side
- ```participation_port```: Port number waiting for a new agent's participate message
- ```local_model_recv_port```: Port number waiting for local model uploads from agents. This will be communicated to each agent who sends a participate message to this aggregator via the welcome message.
##### Agent side
- ```participation_port```: Port number to send a participate message. It needs to match with ```participation_port``` of the aggregator to which the agent sends the message.
- ```sg_model_recv_port```: Port number waiting for global models from the aggregator. This will be communicated to a selected aggregator via a participate message.
- ```path_to_local_file```: Path to the local directory storing the ```state``` and model files. This needs to be unique for every agent (The same one for one pair of ```MLEngine``` and ```Client```).



For example:
```python
python -m fl_main.pseudodb.pseudo_db 1 AUTO
python -m fl_main.aggregator.server_th 1 50001 50002 AUTO
# First agent
python -m examples.minimal.minimal_MLEngine 1 50001 50003 a1 AUTO
# Second agent
python -m examples.minimal.minimal_MLEngine 1 50001 50004 a2 AUTO
```


1. Edit the configuration files in json format in the setups folder. In particular, the agg_threshold can be 1 in this case.
   Also, the "model_names" in config_model file can be ["model1", "model2"].
2. Run the following 3 modules as separated processes in the order of ```pseudo_db``` -> ```server_th``` -> ```minimal_MLEngine```

### [Image Classification Application](examples/image_classification)
This sample provides a simple example of integrating this FL framework into "actual" ML training. Please go to [the prototype directory](examples/image_classification) for more details.


[comment]: <> (## Documentation)
[comment]: <> (![Architecture]&#40;docs/_src/_static/architecture_ver0-5.png&#41;)
[comment]: <> (- [STADLE component specification ]&#40;docs/_src/specs.md&#41;)
[comment]: <> (- [STADLE communication protocols]&#40;docs/_src/protocols.md&#41;)
[comment]: <> (- [STADLE code documentation]&#40;https://tie-set.github.io/stadle_dev/&#41;)


## Contributing

[comment]: <> (### Tech Support / Bug Reports)
Please reach out to our technical support team via [support@tie-set.com](support@tie-set.com) for any issues or bugs.

[comment]: <> (## License)
[comment]: <> (Any use and distribution of this code must be under the NDA with [TieSet Inc.]&#40;https://tie-set.com/&#41;.)

