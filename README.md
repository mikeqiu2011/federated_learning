# Simple Federated Learning System: Educational Version

[comment]: <> (![logo]&#40;docs/_src/_static/logo.png&#41;)


<!-- STADLE platform is a paradigm-shifting technology combining Machine Learning (ML) and decentralized system capability to provide scalable, versatile, and privacy-preserving AI services and applications. 
STADLE stands for Scalable, Traceable, Adaptive, Distributed LEarning.  -->
This repo is the free trial version of a simple federated learning system that is designed with only for educational and R&D purposes to understand the basics of federated learning with minimum architectures and functionalities.
For a commercial version, please contact TieSet Inc. at info@tie-set.com.

Federated Learning (FL) solves many problems of privacy and communication load, which commonly appear in ML systems. FL does not require users to upload raw data to cloud servers.
- Privacy: FL improves the privacy-preserving aspect of AI systems by not collecting data in the cloud while producing collective intelligence based on uploaded user ML models. 
- Communication load: The amount of traffic generated by FL dramatically decreases from classical AI systems due to the difference in data type exchanged.

There are a lot more merits that federated learning systems can provide.

<!-- Our STADLE platform enhances the capability of FL by incorporating decentralized architecture.
- Scalability: Decentralized FL servers in STADLE realizes the load-balancing to accommodate more users.
- 5G-friendliness: The delay in communication to obtain collective intelligence can be dramatically reduced by employing decentralized FL servers located at edge servers.
- Traceability: Our platform has the performance tracking capability that monitors and manages the transition of collective intelligence models in the decentralized system. -->

## Table of Contents
- [Simple FL System: Educational Version](#stadle-v10)
  - [Simple FL Package](#Simple-FL-Package)
  - [Install](#install)
  - [Usage](#usage)
    - [Minimal Example](#minimal-example)
      - [Sample Execution](#sample-execution)
      - [Simulation](#simulation)
    - [Image Classification Application](#image-classification-application)
  <!-- - [Documentation](#documentation) -->
  - [Contributing](#contributing)
  <!-- - [License](#license) -->


## Simple FL Package

### ```examples``` directory
Sample ML Engine codes that integrate FL client side libraries.

### ```fl_main``` directory
Agent, aggregator, database codes together with supporting libraries.

### ```setups``` directory
Configulation files with JSON format and installation yaml files.


## Install
For all the environments of FL Server (Aggregator), FL Client (Agent), and Database Server, please create conda environment and activate it.

```sh
# macOS
conda env create -n federatedenv -f ./setups/federatedenv.yaml
# Linux
conda env create -n federatedenv -f ./setups/federatedenv_linux.yaml
```

[comment]: <> (### FL Client &#40;Agent&#41; )

[comment]: <> (```sh)

[comment]: <> (# macOS)

[comment]: <> (conda env create -n federatedenv -f ./setups/federatedenv.yaml)

[comment]: <> (# Linux)

[comment]: <> (conda env create -n federatedenv -f ./setups/federatedenv_linux.yaml)

[comment]: <> (```)


[comment]: <> (### Database Server)

[comment]: <> (```sh)

[comment]: <> (# macOS)

[comment]: <> (conda env create -n federatedenv -f ./setups/federatedenv.yaml)

[comment]: <> (# Linux)

[comment]: <> (conda env create -n federatedenv -f ./setups/federatedenv_linux.yaml)

[comment]: <> (```)

Be sure to do ```conda activate federatedenv``` when you run the codes.

Note: The environment has ```Python 3.7.4```. There is some known issues of ```ipfshttpclient``` with ```Python 3.7.2 and older```.


## Usage

### Running Database and Aggregator

Here is how to configure the FL server side modules of database and aggregator.
1. Edit the configuration files in the setups folder. The configuration details are explained [here](setups/).
2. Run the following 2 modules as separated processes in the order of ```pseudo_db``` -> ```server_th```.

```python
python -m fl_main.pseudodb.pseudo_db
python -m fl_main.aggregator.server_th
```

### [Minimal Example](examples/minimal)

This sample does not have actual training. This could be used as a template for user implementation of ML Engine.
#### Sample Execution
1. Edit the configuration files (config_agent.json) in the setups folder. The configuration details are explained [here](setups/).
2. Make sure the Database and Aggregator servers are running already. 
   Then, run the minimal example as follows.

```python
python -m examples.minimal.minimal_MLEngine
```
#### Simulation
FL systems can be run multiple agents for simulation within the same machine by specifying the port numbers for agents. 
##### Agent side
```python
python -m examples.minimal.minimal_MLEngine [simulation_flag] [gm_recv_port] [agent_name]
```

- ```simulation_flag```: 1 if it's simulation
- ```gm_recv_port```: Port number waiting for global models from the aggregator. This will be communicated to the aggregator via a participate message.
- ```agent_name```: Name of the local agent and directory name storing the ```state``` and model files. This needs to be unique for every agent.

For example:
```python
# First agent
python -m examples.minimal.minimal_MLEngine 1 50001 a1
# Second agent
python -m examples.minimal.minimal_MLEngine 1 50002 a2
```


1. Edit the configuration files in json format in the setups folder. In particular, the agg_threshold can be 1 in this case.
   Also, the "model_names" in config_model file can be ["model1", "model2"].
2. After running the database and aggregator servers, run the ```minimal_MLEngine``` 

### [Image Classification Application](examples/image_classification)
This sample provides a simple example of integrating this FL framework into "actual" ML training. Please go to [the prototype directory](examples/image_classification) for more details.


[comment]: <> (## Documentation)
[comment]: <> (![Architecture]&#40;docs/_src/_static/architecture_ver0-5.png&#41;)
[comment]: <> (- [STADLE component specification ]&#40;docs/_src/specs.md&#41;)
[comment]: <> (- [STADLE communication protocols]&#40;docs/_src/protocols.md&#41;)
[comment]: <> (- [STADLE code documentation]&#40;https://tie-set.github.io/stadle_dev/&#41;)


## Contributing

[comment]: <> (### Tech Support / Bug Reports)
Please reach out to our technical support team via [support@tie-set.com](support@tie-set.com) for any issues or bugs.

[comment]: <> (## License)
[comment]: <> (Any use and distribution of this code must be under the NDA with [TieSet Inc.]&#40;https://tie-set.com/&#41;.)

